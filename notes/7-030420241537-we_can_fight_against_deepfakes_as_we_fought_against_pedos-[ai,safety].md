AI-safety is one of the biggest buzzwords nowadays. Although, we don't know how to safety-test AI or we don't have a systematic way to prove that AI system under test is safe, we can still fight agains deepfakes as we fough against pedohiles.

CEO of the Conjecture, AI-safety company, Connor Leah thinks that just punishing people who uses deepfake technologies is not enough. We have to attack supply-chain as we did with pedos where we punish people who creates it, who hosts it, who shares it etc.

Additionally, we can make people who builds tools to create deepfakes to be accountable for the potential damage it can cause to society. So, basically we can watermark the videos, images etc. to make it traceable. And, whenever something illegal happens we can track the content back to the source.

It makes sense to some extend and probably will be helpful. But on the other hand Connor Leah thinks we should slow down AI progress by introducing compute-cap where companies which researches AI should have a limit on how much compute they can use. I don't think in this high competitive world, this will be a good idea. It basically assumes that countries like China, Russia will follow the rules. But, in reality they're closed economies and would be very challenging to enforce those rules on them. Therefore, I don't thin American companies will accept this idea of where they're suffering from the rules but others are not. Especially, in a time where Chinese AI researchers are already ahead of American researchers.

[To Stop AI Killing Us All, First Regulate Deepfakes, Says Researcher Connor Leahy](https://time.com/6564434/connor-leahy-ai-risk-deepfakes/)