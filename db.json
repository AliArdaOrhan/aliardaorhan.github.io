[
  {
    "id": 36,
    "title": "Programming is a Thinking Activity",
    "date": "2024-06-17T13:40:00.000Z",
    "tags": [
      "programming"
    ],
    "content": "\n\nThere's a niche discussion in software circles about the nature of software engineering, which I'm delighted to be part of. It basically revolves around whether software is a traditional engineering discipline and whether we can apply the same principles of engineering to software development.\n\nAlthough there's a camp that argues software is an engineering discipline, another camp remains unconvinced. They argue that software engineering represents a radical novelty.\n\nThe main arguments are:\n\n- Programming is a design activity, meaning every single line of code is a design decision at its essence. Programmers are not just throwing code at a well-defined problem. They first understand the problem, then apply design decisions at different levels. Sometimes it's an architectural decision, sometimes it's an OOP abstraction, and sometimes it's just a simple if-else statement. But in every case, developers are applying their design skills to a vague problem.\n- The build phase of programming activity is very different from manufacturing or construction. To understand this better, let's look at it from the other way around. In manufacturing/production, we have to build a blueprint to scale production. That blueprint is carefully designed by engineers and tested many times in different conditions. After the designers of a bridge or physical product are satisfied with the latest design, it's sent to a factory where it's multiplied by heavily optimized machines, and no additional design decisions can be made. In software engineering, design activity and production activity are not separated. When you finish the design activity, its production becomes trivial. You just compile it, which is basically a zero-cost operation. Therefore, anything related to repetition and optimization is not a concern in software engineering. When the design activity is finished, production is finished.\n- Design itself is also problematic in software engineering. Imagine all the entity charts, architectural diagrams, Miro boards, or Jira tickets you have. You can't test any of them. In manufacturing, any design is validated before it goes to production by using simulations, prototypes, real-world tests, etc. And until it's validated to work as expected, it's not sent to production. In programming, we have no way to validate any so-called design artifact. There's no tool that you can feed requirements and an entity-relation diagram to tell you whether you're solving the given problem correctly. When you think about a small scoped ticket, it's not easy to reason about it. But if you start to think on a project level, then you'll understand better what I'm talking about.\n- Every product is a new product even if you're replicating one in the market. Imagine a Mercedes Benz car. Every one of them is exactly the same. You can't get two Mercedes-Benz cars where the engines, electrical systems, or ECUs are wired differently. If they're the same model, they're exactly the same. However, when you're copying an open-source CMS project, you might pick additional or fewer features written in a completely different language, architectural style, and design principles. Yes, you can use some libraries or frameworks to provide some standardization and speed up the process, but the way the solution is built will be very different from the original one.\n- It's almost unnecessary to say it nowadays, but software projects don't scale linearly like manufacturing, where if you add more resources, you get more output. In programming, contextual knowledge is critical for productivity. There's no need for factory workers to understand the process or tools they're building. The only thing they need to do is follow the instructions. However, in programming, in order to come up with a functional solution, you need knowledge. You need to know how to fetch data, which libraries to use to process it, how to store it, how to present it, and most importantly, you need to know which problem you're solving. More people mean more communication overhead, where you need to align more people together. And it takes its toll on productivity. As the famous saying goes, you can't make a baby in one month by adding more developers to the project.\n- Interesting trivia: the term \"software engineering\" was coined by Margaret Hamilton to make the profession cooler as it couldn't draw enough attention from college students. Therefore, the etymology of software engineering is not rooted in its nature but in its marketing strategy.\n\nSo, long story short, programming, or software engineering as we're used to calling it, is dramatically different from other engineering principles. It requires its own understanding, and trying to import other engineering principles under the brand name of agile won't work. It's not about the process you're applying; it's about the mindset your engineers have.\n\nSome good articles around the topic:\n\n- [A radical novelty](https://dl.acm.org/doi/pdf/10.1145/255471.255589).\n- [What is Software Design?](https://www.bleading-edge.com/Publications/C++Journal/Cpjour2.htm)\n- [Why Simple is so Complex?](https://itnext.io/why-simple-is-so-complex-362bc835b763)\n- [Software is Different](https://wiki.c2.com/?SoftwareIsDifferent)\n- [The Source Code Is The Product](https://wiki.c2.com/?TheSourceCodeIsTheProduct)\n",
    "slug": "36-170620240947-programming_is_thinking-[programming]"
  },
  {
    "id": 35,
    "title": "The Right strikes again!",
    "date": "2024-06-13T09:29:00.000Z",
    "tags": [
      "politics"
    ],
    "content": "\n\nWhat a year we're having... On one side, we're planning to colonize Mars, on another side high-tech revolution is on the way with incredible speed, on geopolitic arena war drums can be heard everywhere, and now the right seems to be on the way to power in EU.\n\nAfter the EU elections, It seems like [Le Pen and right-wing parties in France are going into coalition](https://www.politico.eu/article/emmanuel-macron-marine-le-pen-france-brexit-moment-elections-ursula-von-der-leyen-electorate/) with anti-eu and anti-immigrant discourse. It's understandable, there's some sort of negative narrative in prosperous EU countries that they're losing their wealth and power because of uncontrolled and illegal immigration. However, I'm not sure if this is the case.\n\n![Macron vs Le Pen](./macron-lepen.png)\n\nBecause, on the Atlantic side the capability of American economy to innovate and reinvent itself is waaaaay ahead of EU. And, on the Pacific side, China is catching up maybe even surpassing the US. In this scenario, the old continent seems struggling to keep up. There's no Tesla, Apple, Amazon, Microsoft or NVIDIA in Europe. Just think about last 10 years, how many transformative and exciting technology you heard from EU companies? Nothing serious comes to my mind. (Please, compare it with smart phone, ev, ai, cloud computing, etc.) And, most of the time it looks like EU companies are replicating the business model and technologies of their US counterparts. Not different than what China does...\n\nLong story short, I don't think economical problems and stagnation of EU caused by immigrant policy. To my observation, it's more about conservative europeans are not willing to go further with liberal policies which they deemed as a threat to their culture and values. But, the matter of values are also controversial. Are those values of europe open to people who want to be part of it no matter what their races, sexual orientations, religions are? Or, is it some sort of weapons in the hand of right to execute their agenda by using them against lower-class people who has less education and less income? \n\nI'm not sure about the answer. It feels like it's Goliath versus David without slingshot. However, I do believe in universal values and I also believe these values are not under the privilege of any specific countries. It's human heritage where you can track its history to [ancient times of Babylon](https://en.wikipedia.org/wiki/Cyrus_Cylinder). Therefore, attacking them is not only a threat to the EU but also to the whole humanity.\n\nSo, what the European Right promises is vague and not clear. Are we going to risk most peaceful project in human history called European Union, just because of controversial thesis of right-wing parties? I hope not. But, it's clearly a possibility.\n\nSo, I have one question in my mind for those who share the very same concerns with me, where we go when the human achievements are under threat from every sides? What we do?\n\n",
    "slug": "35-130620241031-right_strikes_again-[politics,france]"
  },
  {
    "id": 34,
    "title": "A Heuristic for Developing AI Products",
    "date": "2024-11-06T09:29:00.000Z",
    "tags": [
      "ai",
      "product management"
    ],
    "content": "\n\nHow're we going to build new AI applications? Nowadays, it's one of the most popular questions in the tech industry as the LLM models are all the rage. Don't get me wrong, it's not that straightforward as it seems as models are still hallucinating. Therefore the question of how much we can be sure about the correctness of the outputs that model producing?\n\n[I've came across an article from Ben Evans](https://www.ben-evans.com/benedictevans/2024/6/8/building-ai-products), poplar blogger. He argues that for building AI products we have 2 different paths in front of us.\n\nOne of them is narrowing UI for specific tasks. In this way, a general purpose tool is narrowed down a specific use case and all prompts are built in the interface as buttons, sliders or whatever you can think of. This very heuristic can be used to explain latest boom in coding assistants, marketing toos, knowledge management tools etc.\n\nHowever, what Ben argues more importantly is using these general purpose technologies to build new application which he calls platform-native. For example, Instagram utilised smartphone's, let's call it platform in this case, cameras and computing resources to come up with a native photo-sharing experience. So, basically capabilities of the platform is hid behind the application and invisible to the user.\n\nThat's the heuristic Ben's applying to new type of applications where basic capabilities of platform are hid from users and error-rate is reduced to something ignorable. \n\nI also believe that'll be the path to build technologies that will have transformative effect on our society. Any other addition done to applications like Slack, Email, Zoom etc. are just incremental ones which are nice but won't be impactful as the hype suggests. ",
    "slug": "34-110620241029-heuristic_for_developing_ai_products-[ai,product-management]"
  },
  {
    "id": 33,
    "title": "Agile becomes less cool?",
    "date": "2024-10-06T08:12:00.000Z",
    "tags": [
      "agile",
      "programming",
      "management"
    ],
    "content": "\n\n[Came across an interesting article]((https://www.theregister.com/2024/06/05/agile_failure_rates)) about the failure rates in agile projects. It seems like if requirements **are not** gathered clearly, agile projects tend to have higher failure rates compared to its counterparts. Quoting from the author Dr. Junade Ali: \n\n>\"Our research has shown that what matters when it comes to delivering high-quality software on time and within budget is a robust requirements engineering process and having the psychological safety to discuss and solve problems when they emerge, whilst taking steps to prevent developer burnout.\"\n\nMy practical experiences on the field also supports this. Whenever we do diligent requirements engineering, projects tend to be more smooth and more succesful. But, the contrast is actually more striking. When we don't do requirements engineering very well, we exactly know it'll fail in different ways and it won't be smooth sailing. The latest ticket I've worked on actually demonstrates it very well. \n\nI was tasked to create a robot file without a diligent requirements engineering, therefore I've added links whatever actually make sense for the team. As if that wasn't enough, we've changed the implementation many times as we didn't discuss the requirements for subdomains and other affiliates we have. So, it was like while we were solving the problem, we were designing the solution again and again with each new information we've came across. So, It wasn't pleasant experience to work on something you don't know what needs to be done and you don't know how it'll be done. Could we have avoided this by simply discussing the requirements in a more detailed way? Absolutely.\n\n[Another interesting point made against Scrum is coming from Meijer](https://www.theregister.com/2015/01/08/erik_meijer_agile_is_a_cancer_we_have_to_eliminate_from_the_industry/) where he argues that agile practices and TDD ignores real world practicalities, and focuses on short-term gains. Imagine you're writing an application where you think it'll last for at least 5 years. In this scenario, coming up with a short-cut solution under the name of MVP would be beneficial to realize the value in short time, but its longer term consequences would be paid by more maintenance and more technical debt. And, working in 2 weeks cycle makes it harder as you need to focus on the task at the hand rather than architectural **illities.**\n\nOn the other side, waterfall projects have heavy emphasis on requirements engineering which actually focuses teams to build comphrensive documentation rather than thinking solution's practical aspects. It tends to lead over-documentation and over-engineering.\n\nBut, I think there's a middle ground between those 2 extremes. In agile team's mindsets, I think it's important to make distinction between requirements engineering and big-up front designs. One of them for removing unknowns and helping developers to start their work with a clear understanding of what needs to be done. The latter is for defining how it'll be done and it's mostly futile as there're too much information to process on paper. A setup where product managers and tech leads work together before the sprint to prepare the requirements in a way that team can actually make sense improves productivity significantly. For that purpose, we've set up a meeting each week with product manager to discuss the requirements and, if necessary, to detail them.\n\nLong story short, I'm suggesting agile teams to spend more time on requirement engineering in order to make development experience smoother.\n\n\n\n\n",
    "slug": "33-100620240911-agile_started_become_less_cool-[management,agile,programming]"
  },
  {
    "id": 32,
    "title": "Are agile standups necessary evils?",
    "date": "2024-04-06T07:59:00.000Z",
    "tags": [
      "agile",
      "programming"
    ],
    "content": "\n\nI've came across a blog article that smashes the idea of daily standups. The author argues that most of the standups are rubbish and not useful from the **software engineering** perspective and criticizes the role of scrum masters and stakeholders in the meeting as they usually don't allow developers to discuss the real technical problems they're facing. \n\nAlthough, I'm working for a company which internalized the agile principles and practices, I can't say that I'm a big fan of standups. Most of the times I forget what has been discussed after 5 minutes. To be honest, most of the developers don't know how to update their peers in a concise and productive way. Most of the time what you hear is over-detailed explanation about the situation where you don't have enough context to address it. Therefore, it turns into a monologue where only the speaker is interested.\n\nIn terms of status updates, I can easily say that it can be tracked via Jira board. I personally don't see any value in hearing \"I've worked on this task and I'm still working on it\" every single day. As our team utilizes pair-programming practices everybad, it's very common to hear second engineer to say \"I'm doing same thing as my pair\" which is, you'll appreciate as well, not very useful.\n\nAnd also, I can feel the pain of author when it comes stakeholders and scrum masters. We currently don't have any of those roles in our team but I know how frustrating it is when bunch of people who doesn't understand delicate details of software engineering cut you off when software engineers trying to explain the problem they're facing. My gut reaction is always \"WTF??? Can you let me finish my sentence and let us to discuss the problem?\".\n\nBut, I think agile sailboat has already sailed and it's almost impossible to stop its worshippers. I haven't seen any single company that has abondoned daily standups just because a couple of people think it's not useful. Actually, even it's proved that worshippers won't be changing their mind and, you know, sadly people always find a way to justify their beliefs.\n\nTherefoere, I have a couple of things to make standups more efficient:\n\n- Check the pulse, if team also thinks standups take too much time or inefficient, then you have an oppurtunity to optimize. Otherwise, I wouldn't suggest to touch it. It'll backfire and it'll be weary to convince people to change their precious-but-not-productive habits.\n- If you can, get daily updates in written form. Something in Jira or GDoc would work. Every developer can write what they're working on and whether there's any blocker. This way, the progress can be tracked from a single source and it'll be easier to understand trends.\n- Otherwise, be concise and productive. Have discussions about the problems team's facing at the end of meeting where you can get people a chance to leave meeting. In this way, people won't be in a position that they need to listen something irrelevant for them. \n- Be serious about 15 minutes. If you apply third priniple, your standups will definitely be shorter as it was before. Don't let it slip. Be serious and stubborn about it and any discussion you feel like it's going to extend, postpone it to the end of meeting.\n\n\nIf you follow these 4 simple principles, you'll be able to have very productive and concise standups. Please don't forget that the main goal of standups is to update your peers about your progress and to discuss the problems you're facing. **It's not for problem solving.** \n\n\n[Article can be found here](https://www.lloydatkinson.net/posts/2024/some-thoughts-as-i-sit-here-in-another-standup/?utm_source=tldrwebdev)",
    "slug": "32-040620241015-standups_necessary_evils-[agile,programming]"
  },
  {
    "id": 31,
    "title": "Google Photos AI Update",
    "date": "2025-09-05T07:59:00.000Z",
    "tags": [
      "google",
      "google photos",
      "ai"
    ],
    "content": "\n\nGoogle Photos is receiving a huge update and Gemini will be integrated into it for better searches. We'll be able to query all photos with natural lnaguage like \"list me the last 10 countries that I've visited\" or \"list me photos of people with the most photos\" etc.\n\nI think this is a clear example of how LLM models will be integrated into almost every app. One way or another, they'll be our primary interface for interacting with digital world. And, it's not a promise, it's here. Exciting times...\n\n[Article can be found here](https://www.digitaltrends.com/mobile/the-one-ai-feature-from-google-io-2024-i-cant-wait-for-gemini-google-photos/#dt-heading-first-what-is-gemini)",
    "slug": "31-210520241205-google_photos_update-[google,ai,photos] copy"
  },
  {
    "id": 30,
    "title": "Google Code Review: Too many steps?",
    "date": "2025-09-05T07:59:00.000Z",
    "tags": [
      "google",
      "programming"
    ],
    "content": "\n\nI have to say I'm amazed by the number of steps google take to review any new PR - CL in google context- . They have 2 different tools called Critique and Gerrit. The latter one is used for open-sourced projects meanwhile the first one is used internally. They're very capable and provides good amount of metrics to understand impact radius of the change. You can get a glimpse of Gerrit from [this link](https://chromium-review.googlesource.com/q/status:open+-is:wip).\n\n![Gerrit-Screenshot](./gerrit-screenshot.png)\n\n\nBut, most interesting part is the approval process which requires 3 different set of people. First one is peer-review, where your code is reviewed by your team mates. Second you need to get approval from code owners. And, last but not least you need to get an approval for readability which is very google-specific concept. The idea is that ensuring that the committed code adheres to best possible standards defined in [a lengthy document](https://google.github.io/styleguide/pyguide.html).\n\nHowever, suprisingly instead of increasing cycle time, it actually decreases it. According to researches, google developers spend ***%78 less time than AMD, %75 less than Chrome OS, %79 from Microsoft developers*** on code reviews. Impressive, isn't it?",
    "slug": "30-210520241136-google_code_review-[programming]"
  },
  {
    "id": 29,
    "title": "Tesla cuts 10% of workforce",
    "date": "2025-05-04T07:59:00.000Z",
    "tags": [
      "tesla",
      "ev"
    ],
    "content": "\n\nWow, the second wave of layoffs took its tool on Tesla. After the company announced their deliveries this year fell %8, it seems like they're trying to cut costs to keep the company competitive enough with Chinese EV manufacturers.\n\nThe year has started with big-tech layoffs, and although we didn't expect this it looks like [70000 employees are already laid off until now.]((https://layoffs.fyi/)) I'm not sure where it goes but I'm pretty sure we were already over-staffed and it was necessary to some extend. But, I'll honest last year and this year, the combined number is reached 180k. That's a lot of people.\n\n[Tesla will lay off more than 10% of global workforce: Read the Elon Musk memo\n](https://www.cnbc.com/2024/04/15/tesla-shares-dip-in-premarket-trade-on-global-layoff-reports.html)",
    "slug": "29-170420240957-more_layoffs-[tesla,ev] copy"
  },
  {
    "id": 28,
    "title": "Chip Wars",
    "date": "2025-04-04T08:10:39.000Z",
    "tags": [
      "ai",
      "computing"
    ],
    "content": "\n\nIt seems like chip wars are getting more intense with the latest revalations from Google. They're working on their own version of ARM chips to reduce power consumption and increase performance. Google Axion will have 30% ~ 50% better performance and 60% less power consumption according to Google Cloud CEO Thomas Kurian.\n\nHowever, Google will still be relying on NVIDIA chips. Google's famous products like Blackwell and TPU v5 will still be using chips from the giant. \n\nCompetition is good to be honest. Although, I sincerely believe every company should focus on their strengths rather than fields they don't have expertise or primary focus. Google Cloud in its essence is a cloud provider, not a chip manufacturer. And, intuitevely I can say that these kind of initiatives usually leads to sub-optimal results.\n\n[Google’s new chips look to challenge Nvidia, Microsoft and Amazon](https://qz.com/google-ai-chip-nvidia-axion-arm-microsoft-1851397201)",
    "slug": "28-160420241008-chip_wars-[ai,computing]"
  },
  {
    "id": 27,
    "title": "Slow slow slow shipment! Why?",
    "date": "2025-03-04T09:03:00.000Z",
    "tags": [
      "programming"
    ],
    "content": "\n\n\nInteresting read! Most featured problems are:\n\n- Complicated code base\n- High coupling between different services and libraries\n- Aligning with different stakeholders\n- Waiting for code reviews\n- Writing tests\n\n\n![slow-shipment-reasons](./slow-shipment-reasons.png)\n\n![short-slow-shipment-reasons](./short-slow-shipment-reasons.png)\n\n\nPersonally, I find \"writing tests\" a little bit awkward given that it provides good amount of confidence and safety. And, always pays off in the long run. But, obviously writing tests to legacy code base is a pain in the back.\n\nOther than that, it seems like excessive meeting culture and having a large codebase which didn't get enough attention are the main reasons for slow shipment. I think both of them can be addressable by \n\n- having less people in the loop\n- making teams more autonomous\n- having less \"micro\" microservices.\n- establishing a pair-programming culture\n\nOne way or another, every developer should understand we're paid by the value **we actually deliver**. Therefore, anything that blocks us to do so should be questioned and addressed.\n\n[I asked 100 devs why they aren’t shipping faster. Here’s what I learned?](https://greptile.com/blog/100-devs?utm_source=tldrnewsletter)",
    "slug": "27-150420241051-why_are_slow-[programming]"
  },
  {
    "id": 26,
    "title": "Criticism: Humane's AI PIN",
    "date": "2025-03-04T10:45:00.000Z",
    "tags": [
      "ai",
      "wearables"
    ],
    "content": "\n\nWhen my friend shared it with me, my first reaction was \"how is it different than a mobile phone?\". And, seems like I was right. It's a promising concept but seems like has major shortcomings, especially with interactivity. Nevertheless, I'd like to see its future iterations and how it'll evolve.\n\n[Humane AI Hands-On: My Life So Far With a Wearable AI Pin](https://www.cnet.com/tech/mobile/humane-ai-hands-on-my-life-so-far-with-a-wearable-ai-pin)",
    "slug": "26-150420241045-criticism_humane_pin-[ai,wearables]"
  },
  {
    "id": 25,
    "title": "AI Hype is Over, Now What?",
    "date": "2025-03-04T06:59:00.000Z",
    "tags": [
      "ai",
      "ml",
      "hype"
    ],
    "content": "\n\nSeems like fun is over. \n\nPeople seems they're sturggling to find new ways to increase their productivity with tooling, startups are shutting down, and rest are struggling to keep their valuation high. On the other hand, the general public knows about ChatGPT but nothing else.\n\nAnd, interesting figure is companies spent over 50B on NVIDIA chips but created 3B in return. That's a big number.\n\nHow should we interpret this?\n\n![hype-cycle](./hype-cycle.png)\n\nOne way or another every technology goes through this cycle. AI is no different. First it grabs a lot of attention than it can feed back into its own development. Then, it goes through a period of disillusionment. And, finally it finds its place in the market.\n\nIt seems like we're at the brink of disillusionment step. However, AI revolution is real deal. Compare it with old technologies like internet, electricity, and steam engine. They went through same cycles. At some point, people thought [internet might be overrated.](https://archive.is/EDvpU)\n\n>A winner of the Nobel Prize in Economics, Paul Krugman wrote in 1998, “The growth of the Internet will slow drastically, as the flaw in ‘Metcalfe’s law’—which states that the number of potential connections in a network is proportional to the square of the number of participants—becomes apparent: most people have nothing to say to each other! By 2005 or so, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.”\n\nAfter a period of time and thanks to other innovations in the field, they became the backbone of our society. I don't think it'll be different for AI. It's just a matter of stable time.\n\n[The State of Generative AI, 2024](https://www.thealgorithmicbridge.com/p/the-state-of-generative-ai-2024)\n\n\n\n",
    "slug": "25-150420240859-ai_hype_is_over_now_what-[ai]"
  },
  {
    "id": 24,
    "title": "Robotaxi: One Step Further to FSD",
    "date": "2024-08-04T16:57:00.000Z",
    "tags": [
      "ai",
      "fsd",
      "ev"
    ],
    "content": "\n\n![robotaxi-tweet](./robotaxi-tweet.png)\n\n![tesla-robotaxi](./tesla-robotaxi.webp)\n\nAy yay yaaa!!! Elon's new toy... Robotaxi will unveil itself around August. And, it won't have any steering wheel or pedals. Cool, innit? \n\nAlthough, we haven't seen how Tesla will go around the legal requirements. It's kinda big concern as we haven't see any paperwork done yet. Nevertheless, big step for the industry and for high-tech revolution.\n\n",
    "slug": "24-080420241830-robotaxi_one_step_further_to_fsd-[ai,fsd,ev]"
  },
  {
    "id": 23,
    "title": "Future of Oculus",
    "date": "2024-08-04T10:24:00.000Z",
    "tags": [
      "tech",
      "ai",
      "facebook"
    ],
    "content": "\n\nAfter Facebook bought Oculus 10 years ago, they're having challenges to make AR/VR technology mainstream. There's lack of content and shortcomings of hardware but Meta is progressing.\n\nInterestinly, Fitness is one of the selling point of oculus VR. But, it's contradicting with gaming. Because, you need to take different parameters into consideration if you're building a game or a fitness app. such as temperature, sweating etc.\n\nAnother challenge is controller part. If you're interacting with AR/VR world, you have couple of options such as voice commands, hand gestures and controllers. But, voice commands doesn't present best user experience. It's hard to navigate any UI with your voice. Therefore, Facebook is focusing on controllers which is a novel problem space which we haven't seen since XEROX PARC.\n\nIn terms of content, contrary to Rayban, Meta is focusing on shareability rather than spatial video, in short high-quality experiences are not first priority. Although AI wearables like Humane AI PIN and Rabbit R1 are adding more Gen-AI features into their tools, Meta doesn't have a clear plan for this year. However, they see Gen-AI as a solution to the challenges of creation of metaverse where users can describe their desired space and Ai can create for them.\n\nAlthough Meta's promises are not materialized yet, there's significant progress is going on. And, competition is getting fierce. There're important companies such as Apple are working on this space as well. And, after billions of invesments I just don't want to see Zuckerberg to fail.\n\n[10 Years After Facebook Bought Oculus, What's Next for Meta's VR Plans?](https://www.cnet.com/tech/computing/ten-years-after-facebook-bought-oculus-whats-next-for-metas-vr-plans/?utm_source=tldrnewsletter)",
    "slug": "23-080420241011-future_of_oculus-[tech,ai,facebook]"
  },
  {
    "id": 22,
    "title": "Are we allowed to write our databases? 🫨",
    "date": "2024-07-04T09:42:00.000Z",
    "tags": [
      "dev",
      "database"
    ],
    "content": "\nJoke aside, brilliant work from [Hivekit](https://hivekit.io/) developers. Instead of using heavyweight PostGIS on the top of Postgresql, they just came up with their simple binary format and implemented their own file based database. And, voila! They saved 98% in cloud costs.\n\n**Impressed** 👏👏👏\n\n[How we’ve saved 98% in cloud costs by writing our own database\n](https://hivekit.io/blog/how-weve-saved-98-percent-in-cloud-costs-by-writing-our-own-database/?utm_source=tldrwebdev)",
    "slug": "22-070420241142-are_we_allowed_to_write_our_databases-[dev,database]"
  },
  {
    "id": 21,
    "title": "More Automation, Less Religion",
    "date": "2024-07-04T20:24:11.000Z",
    "tags": [
      "ai",
      "religion"
    ],
    "published": true,
    "content": "\n\n![AI vs Religion](./automation-vs-religion.png)\n\n\nCame across an interesting research that shows with exposure to automation, robots, and AI, people tend to become less religious. It's very counterintuitive, isn't it? I mean, I always thought that with more free time, people would be more likely to spend time on their religious activities. But it seems like it's not the case.\n\nMaybe it shows the shortcomings of existing religions in the modern world. In the end, they're products of their time. And they're designed to control and manage people of that time when science was in its infancy. Interestingly enough, the article also touches on Max Weber's view of science. He once said that science is the \"disenchantment of the world,\" in other words, science replaces supernatural explanations with rational and empirical ones.\n\nBut as researchers also stated, it didn't work well in the past, did it? Positivism of french lost, religion continued. And in some cases, it actually thrived. As a 100% atheist, that's reason I find this research very intriguing. Can the high-tech revolution nail the coffin of religion? Or will they change into something else? Who knows...\n\nHowever, I'm very happy to see that the number of Americans who believe their belonging to a church decreased from 70 percent in 1990 to 47 percent in 2020. In the end, nobody in the world wants a superpower run by religious zealots. It's dangerous... Just remind yourself of the Iraq war.\n\n\n[Where AI Thrives, Religion May Struggle\n](https://www.chicagobooth.edu/review/where-ai-thrives-religion-may-struggle)",
    "slug": "21-070420241124-more_automation_less_religion_[ai,religion]"
  },
  {
    "id": 20,
    "title": "Yes, AI replaces jobs!",
    "date": "2024-04-08T00:09:45.000Z",
    "tags": [
      "ai",
      "jobs"
    ],
    "published": true,
    "content": "\n\nFrom the dawn of the computer revolution, we've lacked a method to analyze how technology affects employment. Finally, we've developed a successful approach. Sadly, it clearly shows that since 1980, technology has been replacing jobs.\n\n> The study uses new methods to examine how many jobs have been lost to machine automation and how many have been generated through “augmentation,” in which technology creates new tasks. On net, the study finds, and particularly since 1980, technology has replaced more U.S. jobs than it has generated.\n\nThey use a new method where they compare US Patent Office data with U.S. Census data, and the findings are interesting.\n\nAround 1940-1980, technology was automating existing jobs but also creating new ones. For example, elevator and telephone operators, typesetters, carpenters, and machinists were automated by machines, but at the same time, shipping clerks, engineers, and department heads were created. After 1980, it seems like automation started to harm employment.\n\nThere are also interesting findings within the study where authors explain that, with the advancement of automation, middle-skill jobs are disappearing, leaving only low-skill and high-skill work. Additionally, they found out that large-scale consumer demand drives technological innovation, rather than entrepreneurs thinking out of the box.\n\nAccording to the authors, this time it's different because AI can be used to replace some high-skill works and also act as a complement to decision-making skills. Therefore, it's challenging to predict the future of employment at this point. \n\n![Rise of robots](./rise-of-robots-book.png)\n\nI see most of the people are pretty optimistic about the future of employment. The main argument is usually technology creates new jobs. And, I remember the same argument was made against the book from Harvard professor Martin Ford, \"Rise of the Robots\", in which he argues most of the jobs are at risk of being automated. To be honest, I'm more pessimistic on this subject. I believe one way or another, most of the jobs that require humans to use computers are at risk of being automated by these new AI technologies. When it comes to the factory floor, it's just a matter of time...\n\n[Does technology help or hurt employment?](https://news.mit.edu/2024/does-technology-help-or-hurt-employment-0401?utm_campaign=Artificial%2BIntelligence%2BWeekly&utm_medium=web&utm_source=Artificial_Intelligence_Weekly_379).\n",
    "slug": "20-070420240945-yes_ai_replaces_jobs-[ai,jobs]"
  },
  {
    "id": 19,
    "title": "Soooo painful to watch 😢",
    "date": "2024-04-06T22:29:00.000Z",
    "tags": [
      "ai",
      "china",
      "britain"
    ],
    "published": false,
    "content": "\n![Britain vs China](./britain-vs-china.png)\n",
    "slug": "19-060420242229-soooo_painful_to_watch-[ai,china]"
  },
  {
    "id": 18,
    "title": "Wow, big revelation... 😳",
    "date": "2024-04-06T22:20:00.000Z",
    "tags": [
      "ai",
      "nvidia",
      "amd"
    ],
    "content": "\n\n![Cousins](./cousins-nvidia-amd.png)\n\nDidn't know this to be honest. CEO of Nvidia and CEO of AMD are cousins.... 2 big figures who are leading the High-tech revolution. Interesting, innit? Should we say it's a family business? haha noooooo.\n\n[Tweet](https://twitter.com/LinusEkenstam/status/1776366399528558879)",
    "slug": "18-060420242217-cousins_amd_nvidia-[ai]"
  },
  {
    "id": 17,
    "title": "Sam Altman and his new toy",
    "date": "2024-04-06T22:05:00.000Z",
    "tags": [
      "ai",
      "openai"
    ],
    "content": "\n\n![Sam Altman and his McLaren](./sam-altman-mclaren.png)\n\nSuch an AI-boy. He reminds me entrepreurs of dot-com bubble. \n\nHe's in every news. He's in every tweet. He's in every meme. He's in every blog posts. He's in every newsletters. He's in every mind. He's in every intuiton. Basically, he's everywhere.\n\n[Tweet](https://twitter.com/historyinmemes/status/1776350068108390770)",
    "slug": "17-060420242205-sam_altman_and_his_mclaren-[ai,openai]"
  },
  {
    "id": 16,
    "title": "American capitalism at its best 🇺🇸",
    "date": "2024-04-06T22:00:00.000Z",
    "tags": [
      "economy",
      "usa"
    ],
    "content": "\n\n![Homeless guys beats helpers](./homeless-beating.png)\n\nHaha, don't know what to feel to be honest. A nice guy who helps homeless person by giving his own clothes gets beaten by the homeless person. It's dark, I know. But, at the same time leaving all those people without access to education, healthcare, shelter, food and so on is signature of American capitalism, innit? So, you reap what you sow huh?\n\n[Tweet](https://twitter.com/bosunatiklama/status/1776590300233744654)\n\n\nDay by day, we're witnessing Chinese AI researchers got ahead of American AI researchers... I think one or another west needs to take his hat off and start to think about what they're doing wrong. And, starting point should be math education.",
    "slug": "16-060420242200-american_capitalistm_at_its-best-[economy]"
  },
  {
    "id": 15,
    "title": "Biruni: A Star in Dark",
    "date": "2024-04-06T20:31:00.000Z",
    "tags": [
      "history",
      "science"
    ],
    "published": false,
    "content": "\n\n![Biruni](/biruni.webp)\n\nI'm researching central asia history around 10th century. It's brilliant place where trade, science, high-culture and wars met. And, after the collapse of Christian culture, it became one of the most important hub for knowledge and grew a lot of bright minds. Biruni was one of them.\n\nHe was borned at 938 at Khwarezm region which is now in Uzbekistan. He spent his first 20 years around that region and studied many different fields suchg as islamic theology, mathemetics, astronomy, medicine and philisophoy. \n\nAfter Samani empire started to lose power, he left his home and moved to Bukhara in which he met with the one of greatest mind of Central asia Ibn Sina (Avicenna). Just to note, Ibn Sina wrote one of most famous book in medicine \"Canon of Medicine\" which was used in European's universities until 17th century.\n\nWith raise of Ghaznavid empire, he was **taken** to the Ghazni alongside with many researchers. Interestingly, Ghaznavid empire brought strict despotism to the region, contrary to his predecessors model of trade-centric autocracies. In short, It represents a downward trend in the region which used to be defined by trade, multi-culturalism, science and art. \n\nTheir leader, ex-slave Mahmud of Ghazni was very rigid sunni muslim and tolerance was not in his dictionary. He waged a war against shia muslims, hindus, zoroastrians and buddhists. He destroyed many temples, libraries and killed thousands of people. Particularly with India raids, he accumulated unbelieveable amount of wealth by looting and imposing high taxes on non-muslims which became some sort of tradition that used by Ottomans until 19th century. But, portraying him as blood-thirsty tyrant would be unfair. At the end, he used that accumulated wealth to build most beautiful architectural pieces and patroned many poets and artists. Although, their only goal was to be sycophants and praise him.\n\nOne thing Mahmud did well was bringing bright people to Ghazni as war booty. And, Biruni was one of them. He went to Ghazni with his own will and spent his brightest 30 years there. \n\nBiruni was into Indian philosophy and science. And, Mahmud's raids opened a door for muslim scholars and Biruni opened that door completely. He spent 13 years in India and traveled different locations. As a result, he wrote 160 books and 20 tract. Although, his all works are not survived, some of them are very important.\n\n- He succesfully calculated and noted latitude and longitude of cities he visited in India. He did this calculations by using methods from two of greatest mathematician of that era Harezmi and Ebu Nasr Mansur bin Irak. \n- He investigated minerals, jeological layers and fossils in India and opened the door for the idea that the world might have not been created as it is and possibly it has been evolved through time, which was an important finding for the era because it's basically against the basic islamic theology.\n- Another striking finding was that he made very accurate calculations about the size of celestial bodies and earth. He calculated the diameter of earth by 16.8 km of its actual value. These results and calculations couldn't be surpassed for 600 years. Later, he calculated a length of a meridian circle and he was only 620 meter away from the actual value. Incredible, innit?\n\n\nOnly with these findings, he earned his place in history. But, what made him unique was his time spent in India where he came up with a book called **Tahqiq ma li'l-Hind (Researches on India)** which is a comprehensive book about India's culture, international relations, religion, history of thought and philosophy. To complete it, Biruni learned sanskrit and studied the work of many different scholars in the region. But, as he lived in a time where Mahmud's religious intolerance was at its peak, he used cautious language. He appraised Indian science and philosophy, but he criticized their scientist and philosophers.\n\nNo matter what, the book is still considered as one of the greatest achievements of Islamic scholoars. And, what significant about this marvelous book is that it rejects all old geometric methods that used before to describe another culture and invented a methods to crystallize the differences between cultures which called comparative studies today. In it, he compares different indian approaches to technological problems and compares them with central asian ones. He also invented a taxonomy to classify different indian poems by their meter and rhyme and represented his findings in a table as we can expect from a modern scholor.\n\nMoreover, according to his view, Empirical evidences can't be comprimised and always beats oral traditions. As a matter of fact, with this view he criticized Buhari's hadiths and if you consider that hadiths are second most important source of islamic theology, you can understand how serious he was about empiricism. Bold move for that time.\n\n\n\n\n\n\n",
    "slug": "15-060420242031-biruni_a_star_in_dark-[history]"
  },
  {
    "id": 14,
    "title": "China's Risky Boot",
    "date": "2024-04-05T20:58:00.000Z",
    "tags": [
      "china",
      "ai"
    ],
    "content": "\n\n![Xi Jinping](/xi-jinping.jpeg)\n\nSame old Economist magazine, same old story. Look how confident they're given their historical record of failed forecasts about China. And yet again, they've just predicted another doom scenario. haha 🤣\n\nAnyways, China seems to respond global economic stagnation by boosting invesments in high-tech industries. They represent this strategy as unleashing new productive forces. And, given that China's property industry was in a bubble and at last it bursted. To come out of it, Xi Jinping seems like leaning over high-productivity and envisions high-tech revolution within the country.\n\nThe scale is incredible...China will spend at least 1.6 trillion dollars in 2024. Almost equals to the half of the invesments in the US. \n\nIt's very interesting because Xi Jinping takes very different route than West has been resorted to, which is stimulating consumers by injecting more money into system. Instead, China is focusing on creating works rather money. Although, it sounds like a good strategy, it's risky as it's not tested before.\n\nClearly, motivations of Xi Jinping can be understandable. We're not living free-trading 2000's any more. And, in this protectionist age, China is preparing its young population to a struggle with USA. And, obviously, whoever wins White House this year, there'll be more tariffs and sanctions on Chinese goods.\n\nHowever, given the track record of China, there's no reason to believe that they can't pull it off. Therefore, I wouldn't bet against China tbh.\n\n[Xi Jinping’s misguided plan to escape economic stagnation](https://www.economist.com/leaders/2024/04/04/xi-jinpings-misguided-plan-to-escape-economic-stagnation)\n",
    "slug": "14-050420242058-chinas_risky_boot-[china,ai]"
  },
  {
    "id": 13,
    "title": "Pair programming with Copilot and ironies of automation",
    "date": "2024-04-05T10:12:00.000Z",
    "tags": [
      "ai",
      "codegen"
    ],
    "content": "\n\nPair-programming is a common practice across the software industry. At first look, it seems like it's doubling the effort and halving the productivity. But, studies shows that it actually adds up 15% to development time while resulting in %15 less error. Some people compares it to having 2 pilots in cockpit. Where second pilot is there to monitor flight and ready to take over.\n\n[Studies](https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality) shows that Since 2022 copy-pasting is on rise. Another study found out that codegen tools deliver code that is valid about 90% of the time, passes 60% of unit tests, and is secure about 60%. \n\nLong story short: AI job is to be fast while yours is to be good. Someone still needs to provide guardrails for the code generated. \n\nOn the other hand, it reminds me [\"ironies of automation\"](https://www.sciencedirect.com/science/article/abs/pii/0005109883900468) research paper where it's stated that as automation increases, human's role becomes more crucial in different ways.\n\nFirst, human needs to monitor the system automated in our case it's the codegen tool we're utilising. To do so, somebody needs to understand what would be the desired output. And, it's not that easy. It requires an experienced pair of eyes to judge whether the code generated is valid, secure and maintainable.\n\nSecond, skills that are not used are deteoriated. So, particularly in our case experienced engineers are in danger of losing their sharpness as they stop thinking about structured problem solving and delegating it to the AI. It applies to junior developers as well. As we all know it, coding is learned by practicing. During the programming, programmers reason about structures, recognized patterns and applies techniques to solve the problem elegantly. How junior engineers will understand validity, quality and security of the code generated if they don't practice it?\n\nSo, I think in a few years codegen tools will become unreplacable part of our daily routine. But, they're not silver bullets and kind of far away from replacing software engineers as of now - Although I believe we'll be replaced in 5-10 year scale. Therefore, my suggestion in this transition period to developers, don't let it to deteriorate your skills. And, keep practicing until you master it. \n\n\n[Developers with AI assistants need to follow the pair programming model](https://stackoverflow.blog/2024/04/03/developers-with-ai-assistants-need-to-follow-the-pair-programming-model)\n\n\n",
    "slug": "13-050420241012-pair_programming_model_for_codegen-[ai,codegen]"
  },
  {
    "id": 12,
    "title": "Why do we use normalization?",
    "date": "2024-04-04T14:37:00.000Z",
    "tags": [
      "stats"
    ],
    "content": "\n\nChatGPT answers:\n\n> Of course! Imagine you have a bunch of different things, like toys, candies, and books. Now, let's say you want to compare them or put them together in a fair way. But toys might be measured in how fun they are, candies by how sweet they are, and books by how many pages they have. It's like comparing apples and oranges!\n>\n> Normalization in statistics is like putting all these things on the same scale so you can compare them easily. It's like if you had a magic machine that makes all toys the same size, all candies the same sweetness, and all books the same thickness. Now, you can compare them much more easily because they're all measured in the same way.\n> \n> For example:\n>\n> **Grades in School:** Let's say you have grades from different subjects like Math, Science, and History. Math grades might go from 0 to 100, Science from 0 to 90, and History from 0 to 80. Normalization would make them all out of 100 so you can compare them better.\n>\n> **Temperature:** You have temperatures in Celsius and Fahrenheit. Normalizing them could make them all in one unit, like Celsius, so it's easier to understand.\n>\n> **Weightlifting:** You have people lifting weights. Some are lifting 50 pounds, some 100 pounds, and some 150 pounds. Normalization might adjust their lifting scores based on their body weight, so it's fair for everyone to compete.\n>\n> So, normalization helps make things fair and comparable by putting them all on the same scale.\n",
    "slug": "12-040420241437-why_do_we_use_normalization-[stats]"
  },
  {
    "id": 11,
    "title": "HireVue: an abomination or what?",
    "date": "2024-04-04T11:52:00.000Z",
    "tags": [
      "ai",
      "hr"
    ],
    "content": "\n\n![HireVue Logo](/hirevue-logo.svg)\n\nI've come across an HR tool called HireVue, which uses AI to analyze video interviews. It's designed to address the first screening interview and provides you with 4-5 different behavioral questions, asking you to record your answers. Then, it analyzes your answers and gives you a score.\n\nThe selling point is that it saves time for HR departments and provides a more objective evaluation. On the other hand, people are frustrated by it, and a couple of Reddit and Quora discussions show that it tends to be found uncomfortable, dystopian, and dehumanizing. [1](https://www.reddit.com/r/recruitinghell/comments/ycxn19/anyone_ever_did_a_video_interview_with_hirevue/) [2](https://www.reddit.com/r/recruitinghell/comments/kd1q4w/fuck_hirevue_and_any_company_that_makes/) [3](https://www.quora.com/HireVue-offends-me-Am-I-officially-an-old-dog)\n\nI have mixed feelings about it. As a firm believer in AI-based systems, I see it as a huge step in empowering us with AI-based solutions and always think that data beats opinion. Additionally, I find the bias problem addressable to some extent with tweaking the parameters that model is using.\n\nOn the other hand, accusing models of having bias while ignoring human biases, perspectives, and perceptions seems unfair to technologists. I sincerely believe that even if models have biases, they'll outperform any human being. Therefore, these kinds of explosive comments started making me think that people are missing the point. Humans are not perfect at all... **And machines can help us.**\n\nSo, long story short, in an environment where a job posting receives hundreds of applications, using these models to filter out candidates who wouldn't fit the role would result in better outcomes than incompetent, junior talent acquisition specialists.\n\nSo, the sun is shining, the birds are singing, and AI is coming. Let's embrace it.\n\n[HireVue](https://www.hirevue.com/)\n\n",
    "slug": "11-040420241152-hirevue_abomination_or_what-[ai,hr]"
  },
  {
    "id": 10,
    "title": "Traditional media loses blood",
    "date": "2024-04-04T10:43:00.000Z",
    "tags": [
      "media"
    ],
    "content": "\n\nWohooo... What a year... AI, EV, Wars, Scandals and so on. But, Obviously not for traditional media. \n\nElon Musk has ignited a conversation about the current status of traditional media and as you guys already know he's not a biggest fan of them. But, tweets contain 2 charts which clearly shows that media giants Bloomberg and WSJ clearly losing their organic traffic. After the invention of world wide web, they were obviously losing their power however it's evident that we're passing a critical threshold here.\n\n![Bloomberg](/bloomberg-organic-traffic.jpeg)\n\n![WSJ](/wsj-organic-traffic.jpeg)\n\nBut, is it really a good thing? Obviously, Internet is the great equalizer. But, it's also a place where millions of people who claim to have the truth share their opinions which are mostly crafted through their biases, beliefs and subjective experiences. It's overwhelming to keep up with it. And, not interestingly, the social media is designed to keep you engaged which actually favors the most entertaining and controversial content rather than the most truthful one.\n\nDon't get me wrong. I'm not saying traditional journalism should come back. But, I think we should be more cautious about how journalism will look like in the future and how we can make it better, in which I don't have slightest idea.\n\n\n\n\n",
    "slug": "10-040420241043-traditional_media_loses_blood-[media]"
  },
  {
    "id": 9,
    "title": "Tesla sales drop significantly",
    "date": "2024-04-04T10:08:00.000Z",
    "tags": [
      "ev",
      "tesla"
    ],
    "content": "\n\nAccording to CNBC-E Tesla sales drop significantly in the first quarter of 2024. Company expected to sell 440.000 cars but numbers are around 360.000. Due to this, share numbers dropped 8.5%.\n\nIt starts to feel like competition from BYD and Xiaomi is starting to take a toll on Tesla. Let's see what will be the Elon's next move. \n\n[Tesla shares fall after deliveries drop 8.5% from a year ago](https://www.cnbc.com/2024/04/02/tesla-tsla-q1-2024-vehicle-delivery-and-production-numbers.html?utm_source=tldrnewsletter)",
    "slug": "9-040420241008-tesla_sales_drop_significantly-[ev,tesla]"
  },
  {
    "id": 8,
    "title": "US to ban TikTok which is an empty threat",
    "date": "2024-04-03T15:59:00.000Z",
    "tags": [
      "tech",
      "safety"
    ],
    "content": "\nCongress passed a bill to ban tiktok which seems like an empty threat. First of all, it's against freedom of speech which would make bill subject to judical review. If you combine this with Tiktok is storing US data in Oracle's servers, it's not clear how Congress can validate their reasoning. \n\nAdditionally, the law itself is unenforcable. It would prevent TikTok to be distributed in US but it wouldn't prevent people to use it. \n\nLast but not least, it doesn't solve the actual problem which is that China is gathering sensitive data from US citizens. Congress ignores that most of tech companies collect these data and sells them through data brokers. Furthermore, the data collected by Tiktok is not that sensitive. It's more about social media usage, location data etc.\n\nSo, it seems like the proposed ban is rather a economical move to force owner company(ByteDance) to sell it to US owners.\n\n[The House TikTok Ban Is an Empty Threat](https://time.com/6962823/house-tiktok-ban-is-an-empty-threat/)",
    "slug": "8-030420241559-us_to_ban_tiktok_which_is_an_empty_threat-[tech,safety]"
  },
  {
    "id": 7,
    "title": "We can fight against deepfakes as we fought against pedohilia",
    "date": "2024-04-03T15:37:00.000Z",
    "tags": [
      "ai",
      "safety"
    ],
    "content": "\n\nAI-safety is one of the biggest buzzwords nowadays. Although, we don't know how to safety-test AI or we don't have a systematic way to prove that AI system under test is safe, we can still fight agains deepfakes as we fough against pedohiles.\n\nCEO of the Conjecture, AI-safety company, Connor Leah thinks that just punishing people who uses deepfake technologies is not enough. We have to attack supply-chain as we did with pedos where we punish people who creates it, who hosts it, who shares it etc.\n\nAdditionally, we can make people who builds tools to create deepfakes to be accountable for the potential damage it can cause to society. So, basically we can watermark the videos, images etc. to make it traceable. And, whenever something illegal happens we can track the content back to the source.\n\nIt makes sense to some extend and probably will be helpful. But on the other hand Connor Leah thinks we should slow down AI progress by introducing compute-cap where companies which researches AI should have a limit on how much compute they can use. I don't think in this high competitive world, this will be a good idea. It basically assumes that countries like China, Russia will follow the rules. But, in reality they're closed economies and would be very challenging to enforce those rules on them. Therefore, I don't thin American companies will accept this idea of where they're suffering from the rules but others are not. Especially, in a time where Chinese AI researchers are already ahead of American researchers.\n\n[To Stop AI Killing Us All, First Regulate Deepfakes, Says Researcher Connor Leahy](https://time.com/6564434/connor-leahy-ai-risk-deepfakes/)",
    "slug": "7-030420241537-we_can_fight_against_deepfakes_as_we_fought_against_pedos-[ai,safety]"
  },
  {
    "id": 6,
    "title": "Are we outsmarted by machines?",
    "date": "2024-04-03T14:58:00.000Z",
    "tags": [
      "ai",
      "agi"
    ],
    "content": "\nSince 1960's we've been discussing about machines that can outperform human capabilities. And, most of the predictions were wrong. But, 2022 with the advancements in LLM modals, the debate heated up again.\n\nEspecially, given the [scaling laws for neural language models](https://openai.com/research/scaling-laws-for-neural-language-models), some CEO's like Sam Altman, Dario Amaradei thinks that in the next 5 years, we'll have AGI (Artificial General Intelligence) which can outperform human at any cognitive task.\n\nOn the other hand, AI experts that are asked about when high-level intelligence machine will come, their predictions seemed to be updated from 2060 to 2047 in one year. There're a lot of uncertainties in the field. And, also people like Tetlock warns us that expert forecasts are usually wrong as history shows.\n\nOn the other hand, Hubert Deyfus actually thinks that interpreting current methodologies as evidence of AGI is like seeing first monkey climbed a tree as evidence of a moon landing. So, a little bit of skepticism is needed.\n\nHowever, most of the people agree that around 2030 AI systems will be able to do individual tasks better humans. For example, experts predict that first best-seller book will be written by a machine around 2029. And, around 2028, AI will hit top 40 in the music charts.\n\nOn philosophical side, definition of intelligence and how current AI systems fit into that definition might be a still big debate. However, for mere mortals like us, all of these technologies already outperformed us in many ways. They can write code, write articles, play games, drive cars better than us. For people, they're already smart whether they have human-level intelligence is a academic question rather than practical one. \n\nI think most important question for us at this point is what would be the impact of these new technologies on our lives and how we can prevent them from being used in a harmful and descructive way.\n\n\n[When AI outsmart humans](https://time.com/6556168/when-ai-outsmart-humans/)\n\n",
    "slug": "6-030420241458-are_we_outsmarted_by_machines-[ai,agi]"
  },
  {
    "id": 5,
    "title": "AI Safety is a Myth or Reality?",
    "date": "2024-04-03T14:36:00.000Z",
    "tags": [
      "ai",
      "safety"
    ],
    "content": "\n\nRead an article about METR which is non-profit organization for safety-test of AI. It seems like nobody knows how to safety-test AI and METR specifically focusing on whether AI bots can self-replicate itselves and spread through internet. Because, if it can, then it'll be challenging to turn off AI bots. \n\nBut, it's also a pragmatic decision as it requires less specialized expertise than, say, biosecurity testing. Anyways, it's an important topic where 15 different AI companies also commit to have responsibility to test new models for self-replicating techniques.\n\nIt sounds like safety-test will become very crucial in the future.\n\nNIST president [Elham Tabassi](https://time.com/collection/time100-ai/6310638/elham-tabassi/) says that community doesn't have an answer for systemic approach at the moment.\n\nIt seems like [we have only 5 years left](https://time.com/6564434/connor-leahy-ai-risk-deepfakes/) before AI could pose an existential threat to humanity.\n\nAnd some company CEO's, like Meta and Cohere, says METR tests are far-fetched. I also agree with this sentiment. I think current LLM modals are far-away from self-replicating. I think danger lies in misusing AI technologies by humans rather than AI itself. People can create synthetic videos, deepfakes, voices etc. and spread them through internet. I think this is the real danger not self-replicating AI bots.\n\n[Nobody Knows How to Safety-Test AI](https://time.com/6958868/artificial-intelligence-safety-evaluations-risks)\n",
    "slug": "5-030420241436-ai_safety_is_a_myth_or-[ai,safety]"
  },
  {
    "id": 4,
    "title": "OpenUI: Future is coming",
    "date": "2024-04-03T12:31:00.000Z",
    "tags": [
      "ai",
      "design"
    ],
    "content": "\n\n![OpenUI Demo](/openui-demo.gif)\n\nJust had a chance to play with OpenUI's new toy. It's basically LLM engine to build UI's step by step with prompt engineering. For a long time we were having discussions around how AI based tools might impact our future. Debates got heated and divided people into two camps. One camp was saying that AI can't do what software engineers do, such as architecting, tech-debt & complexity management, code reviews, performance optimizations, dependency analysis etc.\n\nBut, most of these people are missing a key point which is that the change will be huge it'll change all domain language we're using. Basically the question here is define tech-debt & complexity in ai world.\n\nThere's a mantra says that [**code is read more than written**](https://www.goodreads.com/quotes/835238-indeed-the-ratio-of-time-spent-reading-versus-writing-is). That's true in a world where most of the code is written and reviewed by humans. But, do we really think it'll be same in AI based software engineering? I don't think so. \n\nArchitecture, complexity, code reviews are human construct. They're not universal facts that machine can operate on. They're based on human experiences. And, as we know, AI can't experience. It can only learn from data.\n\nSo, long story short, I think we're at the brink of a new era where everybody will become prompt engineer including designers, product managers, people managers and obviously engineers. It's an exciting age to be in.\n\n[Link](https://github.com/wandb/openui)",
    "slug": "4-030420241231-openui_future_is_coming-[ai,design]"
  },
  {
    "id": 3,
    "title": "At last... Apple is working on AI empowered Siri",
    "date": "2024-04-03T11:36:00.000Z",
    "tags": [
      "apple",
      "ai"
    ],
    "content": "\n\nSiri researchers are working on a new AI empowered modal that will outperform chatgpt-4. Benchmarks are completed against ChatGPT-4. What they're doing is basically feeding their new LLM modal ReaLM with screenshots. It'll be very interesting to see them compete with OpenAI. I think Apple has a lot to give in this space.\n\n[Link](https://9to5mac.com/2024/04/01/apple-ai-gpt-4/?utm_source=tldrai)",
    "slug": "3-030420241136-apple_is_working_on_ai_empowered_siri-[apple,ai]"
  },
  {
    "id": 2,
    "title": "China has an serious edge on AI talent",
    "date": "2024-04-03T09:59:00.000Z",
    "tags": [
      "ai",
      "china"
    ],
    "content": "\n\nI've just read a blog post about how China is leading on AI talent. Appearently, China is leading world on producing AI talents. And specifically, it's not just in China also in United States, Chinese people becoming increasingly more dominant in AI field.\n\nAccording to the research, Chinese researches **make up 38 percent of the top AI researches in the United States** at the moment. The number was **27 compared to 3 years** before. Currently, **Americans make up for 37 percent and it was 31 percent 3 years before.**\n\nInterestingly, China is more focused on manufacturing capabilities rather than digital technologies like ChatGPT etc.\n\nAnd also, with the latest development in law system, some chinese researchers are prosecuted for sharing their research with the Chinese goverment. \n\nAs a result, more chinese researchers tend to stay in China rather than migrating to United States. It might have impact on competitiveness of United States in AI field. But, more interestingly it clearly shows that China is ahead of United States in talent-growing. It'll have important impact.\n\n[In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent](https://www.nytimes.com/2024/03/22/technology/china-ai-talent.html)",
    "slug": "2-030420240959-china_has_an_edge_on_ai_talent-[ai,china]"
  },
  {
    "id": 1,
    "title": "Talent vs Culture Problem",
    "date": "2024-04-02T15:43:00.000Z",
    "tags": [
      "management"
    ],
    "content": "\n\nAfter 12 years of software engineering, including 6 years of team management experience, I came to conclusion that modern management theory doesn't work. Most of those principles, techniques and frameworks hit the wall when there's a information asymmetry between you and your peers. Most of the people are driven by their biases, perspectives and perceptions rather than data. Here are some of my observations:\n\n- Happiness and performance is negatively correlated in most cases. I've never seen a team that is highly efficient and happy at the same time. When I say highly efficient, I'm not talkin about producing more work. I'm talking about producing more with higher quality. \n- Only way to have a happy and performative team is finding the right people who become happy as they become more productive. These people are rare and if you're mediocere company, the chances you find them are very very low.\n- Even if you find some, because surrounding culture doesn't appropriate the same characteristics, they'll be extremely unhappy. In worse cases, they'll be problematic as they can't fit into the company.\n- Most of the hiring managers becomes very happy whenever they encounter these rare breeds. But most of those managers are not equipped well to manage these people. They're driven by their biases, perspectives and perceptions. They're not interested in data. They're interested in their opinions.\n- Especially, it become more problematic when most of those managers starts to feel incompetent and gets into some sort of competition with those people. Interestingly, they always do. Most common tactic is using other peoples opinions about these talents to oppress them and play some sort of power game. \n- These eyes saw extremely productive people put in PIP programs because they don't give answers others like. They're accused to be aggresive, uncollaborative, uncommunicative etc.\n- As a result, it ends up with a disaster. These people are either fired or they leave the company. \n\nAll of this brings us a siatution where I think modern management practices fails. Because, it doesn't deliver the basic premise of it, which is as you get those principles, you'll get better results. But, in reality it actually ends up in personal tragedy where you think you're doing correct thing, while others try to persuade you that you're actually wrong.\n\nBut, let me be honest, I think most of the companies around the world are in this situation. They're valuing artificial harmony over productive conflicts. The peter principle is usually the case. Good engineers became managers without necessary skillset and causes good talents to be oppressed. \n\nSome might argue that not every company is a good company. But, the biggest problem about it is basically these priciples are not applicable. It ends up with worse results rather than better ones. At the end we left with mediocre talents working for mediocre companies where people protect their turf rather than working for a common goal.",
    "slug": "1-020420241543-talent_vs_culture_problem-[management]"
  }
]